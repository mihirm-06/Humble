{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 16:04:59.106943: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# Imports #\n",
    "###########\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "###############################\n",
    "# Data import & Preprocessing #\n",
    "###############################\n",
    "\n",
    "sp_txt = \"Data/ShakespeareInsults.txt\"\n",
    "nj_txt = \"Data/NickiMinaj.txt\"\n",
    "dt_txt = \"Data/trump_data_with_caps_periods.txt\"\n",
    "gr_txt = \"Data/gordonramsayinsults.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "######################\n",
    "# Def Train Function #\n",
    "######################\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def train_model(txt, steps, output_path):\n",
    "    model = aitextgen(tf_gpt2=\"124M\", to_gpu=True)\n",
    "    model.train(txt,\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=steps,\n",
    "         generate_every=500,\n",
    "         save_every=500,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         fp16=False,\n",
    "         output_dir=output_path,\n",
    "         batch_size=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#######################\n",
    "# Training the models #\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 14:59:41.755589: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting TensorFlow checkpoint from /projects/20faf27f-1124-4aa0-b984-e0c449973ff4/Project/aitextgen/124M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h1/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h10/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h11/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h3/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h4/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h5/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h6/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h7/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h8/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/attn/c_attn/b with shape [2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/attn/c_attn/w with shape [1, 768, 2304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/attn/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/attn/c_proj/w with shape [1, 768, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/ln_1/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/ln_1/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/ln_2/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/ln_2/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/mlp/c_fc/b with shape [3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/mlp/c_fc/w with shape [1, 768, 3072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/mlp/c_proj/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/mlp/c_proj/w with shape [1, 3072, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/ln_f/b with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/ln_f/g with shape [768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/wpe with shape [1024, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/wte with shape [50257, 768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'ln_1', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'ln_1', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'ln_2', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'ln_2', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'w']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['ln_f', 'b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['ln_f', 'g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['wpe']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialize PyTorch weight ['wte']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save PyTorch model to aitextgen/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save configuration file to aitextgen/config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555c1b4f7de04a79bee7fbcecb459b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 6,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
      "  rank_zero_deprecation(\n",
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:171: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afca5ac963f44f8834a6f27c15b43c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 6,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2281: LightningDeprecationWarning: `trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7. Use `ProgressBarBase.get_metrics` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500 steps reached: saving model to /model/sp_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "Thou reeky base-court vassal.\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: saving model to /model/sp_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,500 steps reached: saving model to /model/sp_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,500 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "Thou art the cap of all the fools. \n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,000 steps reached: saving model to /model/sp_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "Thou spleeny tickle-brained coxcomb.\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,500 steps reached: saving model to /model/sp_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,500 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "Away, you three-inch fool! \n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3,000 steps reached: saving model to /model/sp_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " the tartness of his face sours ripe grapes. \n",
      "\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "# Shakespeare\n",
    "sp_ai = train_model(sp_txt, 3000, 'model/sp_ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec2ccce70914c12943b5fc3967d6222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 7,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a1f92623244fb0955c4b7d5b345b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 7,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500 steps reached: saving model to /model/nk_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ", I'm finicky, I'm picky.\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: saving model to /model/nk_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Everybody gon' see where I'm lyrically at; used to hate Nicki, now they givin me dap.\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,500 steps reached: saving model to /model/nk_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,500 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "You bad, but Nicki is badder Step ya cookies up, go get you a ladder.\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,000 steps reached: saving model to /model/nk_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "White girls tell me hey, Nicki your camp rules. Is that why you get more head than shampoos.\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,500 steps reached: saving model to /model/nk_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,500 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "White girls tell me hey, Nicki your camp rules. Is that why you get more head than shampoos.\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3,000 steps reached: saving model to /model/nk_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Forget barbie, fu.. Nicki, she's fake. She's on a diet but my pockets eating cheesecake.\n",
      "\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "# Nicki Minaj\n",
    "nk_ai = train_model(nj_txt, 3000, 'model/nk_ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5344100996d45f885cbc307e68df3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 4,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin already exists in /model/dt_ai and will be overwritten!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
      "  rank_zero_deprecation(\n",
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:171: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29b7d6022564b6f96654b9d5ff93113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 4,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2281: LightningDeprecationWarning: `trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7. Use `ProgressBarBase.get_metrics` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500 steps reached: saving model to /model/dt_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      " many dishonest reporters.fake news suppression polls.they show phony polls just like they report fake polls.never even show up to vote.worst pollsters.produced so poorly compared to the fake news media.our country can't get any worse.they make up fake stories in order to get attention.few people know that fortune magazine is still in business.considered the worst fbi director in the history of its political system.long and boring.w boring.not good!not good!not good!only makes bad deals!not good!not at stopping people from flowing into mexico through their southern border.they must stop the big drug and people flows, or i will stop their cash cow, nafta.has no effective border laws.slow walking, or even less stamina.terrible.obstruction!obstructionists!report the great (hacking) i won big, and easily won!the most inaccurate (and fraudulent) case of (1,000) in the history of american politics.never wins elections!didn't do a very poor very poor job!terrible, inaccurate and even fraudulent numbers.russian collusion with the trump campaign.get the facts straight.they don't want to report the facts.just want\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: saving model to /model/dt_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,500 steps reached: saving model to /model/dt_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,500 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "just a continuation of the dnc.slanted, with the democrat party in the midterms.13 angry and conflicted democrats.the worlds most expensive witch hunt.a phony scam.i have never seen.a very bad show with their fake news.the worst of them all!a total scam on a scale not seen before.a tremendous waste of time and energy.on a new phony kick about my management style.very expensive and unpopular.flat broke and unconstitutional!18 angry democrats.will never be satisfied with anything we give them.always resist and obstructing.nothing will ever come them.the greatest hoax.trump hater.sleepy joe.a total fraud on your president and the american people!watch out for people that take so-called notes on your show.bad ratings,  a disgrace to our country.has become so partisan, distorted.doesnt understand what the word demagoguery means.failed on transition.upset that they were saying when i wouldnt be doing in their own card - now hell be doing poorly.doesnt understand what the word demagoguery means.failed on transition.should be ashamed of herself\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,000 steps reached: saving model to /model/dt_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      " be laughed at all over the world,a total joke,sick and bad,what the hell has happened to them.bad, in perhaps the end,made all sorts of crazy charges,can't believe how badly @cnn has done in the ratings,lyin james comey? take away millions of dollars a year, while charging amazon and others.must pay a big story about me.disgraceful!totally untrue.lies in congress.he is supposed to know the law.guilty on so many charges unrelated to me.they want to scare everybody into making up stories that are not true by catching them in the smallest of misstatements. sad!old, very costly & anti-usa.failed prognosticator.never had a clue.pathetic and dishonest.flat broke and out of business.rest in peace!such a big story that will never be covered by the fake news.anarchists, agitators, and looters.unstable.rightfully shunned, scorned and mocked.never liked, and mocked.never liked, quote anonymous sources (who don't got fired)such a mess.nothing works.all.a low-life who should suspend him for remainder of\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,500 steps reached: saving model to /model/dt_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,500 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3,000 steps reached: saving model to /model/dt_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ".\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3,500 steps reached: saving model to /model/dt_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3,500 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4,000 steps reached: saving model to /model/dt_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "trying to extort $1,000.00 from me.mormons don't like liars!the man who choked and let us all down.a mixed up man who doesn't have a clue. no wonder he lost!never worth watching.the most overrated person on tv.one of the dumbest of all pundits.he has no sense of the real world!dummy!so average in so many ways!looks and sounds so ridiculous.just another dishonest politician.obsolete.all talk and no action!a hell hole.a mess.a mess.failing so badly that it will soon be taken off thr air.another phony hit job on me.totally biased.losing big.really one-sided and unfair reporting.got thrown off of tv by nbc.fired like a dog!a dumb group!in total disarray.almost everybody quitting.bad, dishonest journlists.attacked new yorkers and new york values- we don't forget!unqualified to be president.covers me so inaccurately.i win a state in votes and then get non-representative delegates because they are offered all sorts of goodies by cruz campaign\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4,500 steps reached: saving model to /model/dt_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4,500 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "ings are way down!should issue an apology to america!no matter what i do or say, they will not write or speak truth,out of control!low news and reporting standards,fake news networks,just made up,fighting for the violent ms-13 killer gangs & sanctuary cities,dealing with the democrats for their very unfunny & repetitive material,always anti-trump!so knowingly inaccurate with their reporting,badly broken, big premiums,one-sided coverage,disrespecting our country,begged me to endorse him for re-election,i said no and he dropped out,largely responsible for the horrendous iran deal!a negative voice,in the way of our great agenda,didn't have the guts to run!gave us the iran deal, & that's about it,showed such disrespect for country!with jemele hill at the mike, it is no wonder espn ratings have 'tanked,' in fact, tanked so badly it is the talk of the industry!getting massive tax breaks while at the same time disrespecting our anthem, flag and country,it is no wonder espn ratings have 'tanked,' in fact, tanked\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5,000 steps reached: saving model to /model/dt_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      " and not for the great state of kentucky,many polls are much better,if it is fake news @washingtonpost, add 10 points!all the news thats not fit to print,it is hell dealing with the dems,gretchen half whitmer,way in over her head,blaming everyone for her own ineptitude & ineptitude,a third rate reporter who has nothing going.a fake news journalist.such fake reporting.corrupt and disgusting.lamestream media  very dangerous & corrupt people, who have totally and cant even speak up and have zero presence.a waste of time.little adam schiff.part of the crookeds emails is corrupt.fake news media, fake news media, and all bad for our country.a total disaster.fake news media,  crazy.always seeking to make me look as bad as possible.did a bad interview.so bad for the worker of bernie sanders.lyin brian williams.totally fabricated a war story.a very dishonest journalist!forgot the people who got them there.watching @foxnews weekend anchors is worse than\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "# Donald Trump\n",
    "dt_ai = train_model(dt_txt, 5000, 'model/dt_ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409b1baf121f49ff96f316783d1e32e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 4,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
      "  rank_zero_deprecation(\n",
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:171: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a55065df4ce45c3b1344c965408b952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 4,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2281: LightningDeprecationWarning: `trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7. Use `ProgressBarBase.get_metrics` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500 steps reached: saving model to /model/gr_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ".\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: saving model to /model/gr_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Youm not critic-proof, and I still take it personally, but I take it less personally now.\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,500 steps reached: saving model to /model/gr_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,500 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,000 steps reached: saving model to /model/gr_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "Stop taking things personally.\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,500 steps reached: saving model to /model/gr_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2,500 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Im Gordon Ramsay, for goodness sake; people know Im volatile.\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3,000 steps reached: saving model to /model/gr_ai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "You used so much oil, the U.S. want to invade the fing plate.\n",
      "\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "# Gordan Ramsey\n",
    "gr_ai = train_model(gr_txt, 3000, 'model/gr_ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "##################\n",
    "# Load the model #\n",
    "##################\n",
    "\n",
    "sp_ai = aitextgen(model_folder=\"model/sp_ai\")\n",
    "nk_ai = aitextgen(model_folder=\"model/nk_ai\")\n",
    "dt_ai = aitextgen(model_folder=\"model/dt_ai\")\n",
    "gr_ai = aitextgen(model_folder=\"model/gr_ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#####################\n",
    "# Generating output #\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mJun\u001b[0m face is not worth sunburning.\n",
      "\n",
      "==========\n",
      "\u001b[1mJun\u001b[0m, and proud coward, an hourly promise breaker, the owner of no one good quality.\n",
      "\n",
      "==========\n",
      "\u001b[1mJun\u001b[0m.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==========\n",
      "\u001b[1mJun\u001b[0m face, So full of frost, of storm, and cloudiness. \n",
      "\n",
      "==========\n",
      "\u001b[1mJun\u001b[0m, I have done thy mother. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shakespeare Generate\n",
    "sp_ai.generate(n=5, \n",
    "              batch_size=5, \n",
    "              prompt=\"Jun\", \n",
    "              min_length=10, \n",
    "              max_length=100, \n",
    "              temperature=1, \n",
    "              top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the enemy of the people, will do anything, they can to do to, get the justice.\n",
      "Ive got to be boisterous to get results.\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "# trump grammar fixer (i hope)\n",
    "import string\n",
    "\n",
    "def fix_grammar(input):\n",
    "    end_punc = '.?!'\n",
    "    no_first_letter = True\n",
    "    fixed_grammar = ''\n",
    "    index = 0\n",
    "    for index in range(len(input)):\n",
    "        char = input[index]\n",
    "        if char not in string.ascii_letters and no_first_letter:\n",
    "            #if the first character isn't a letter, it ignores it until it finds a letter\n",
    "            continue\n",
    "        elif char in string.ascii_letters and no_first_letter:\n",
    "            #if it finds the first letter, it adds it to the edited version\n",
    "            no_first_letter = False\n",
    "            char = char.upper()w\n",
    "            fixed_grammar += (char)\n",
    "        elif char == ',' and input[index+1] != ' ':\n",
    "            #if it findas a comma with no space after it, it will add the comma and a space to the edited version\n",
    "            fixed_grammar += ', '\n",
    "        elif char == ' ' and input[index+1] == ' ':\n",
    "            #if it detects a double space it doesnt add the first space, and so on until there's only one space\n",
    "            continue\n",
    "        else:\n",
    "            fixed_grammar += (char)\n",
    "        if char in end_punc:\n",
    "            break\n",
    "\n",
    "    print(fixed_grammar)\n",
    "\n",
    "fix_grammar(', is the enemy of the people, will do anything,  they can to do to,get the justice.will never get anything done.')\n",
    "fix_grammar('ive got to be boisterous to get results.')\n",
    "fix_grammar('Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRaj\u001b[0m is who you ain't fu..in' with\n",
      "\n",
      "==========\n",
      "\u001b[1mRaj\u001b[0m. What shes delivering to the world now is basically what they want. But I know that shes a super talented superstar who can do anything at a high levelrap, sing, act, whatever she wants to do. This is just the beginning of Nicki Minaj. Her best is yet to come. In my opinion she is as talented as my other girl Lauryn Hill. They have completely different styles. But as far as the talent is concerned they both can do\n",
      "==========\n",
      "\u001b[1mRaj\u001b[0m a show for Versace, they request me by name and if they don't get Nicki, it just won't be the same.\n",
      "\n",
      "==========\n",
      "\u001b[1mRaj\u001b[0m? Now lets get nasty.\n",
      "\n",
      "==========\n",
      "\u001b[1mRaj\u001b[0m is who you ain't fu..in' with\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nicki Minaj Generate\n",
    "list = nk_ai.generate(n=1, \n",
    "               batch_size=5, \n",
    "               prompt=\"Raj\", \n",
    "               max_length=100, \n",
    "               temperature=1, \n",
    "               top_p=3,\n",
    "               return_as_list=True)\n",
    "\n",
    "print(list)\n",
    "print('================================')\n",
    "fix_grammar(list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groot in the ballot boxes (on video), double voters, dead voters.\n",
      "Groot\n",
      ".\n",
      "Groot a new voter fraud.\n",
      "Groot no information about the sample.\n",
      "Groot commission.\n"
     ]
    }
   ],
   "source": [
    "# Donald Trump Generate\n",
    "list = dt_ai.generate(n=5, \n",
    "               batch_size=5,\n",
    "               prompt=\"Groot\",\n",
    "               min_length=10,\n",
    "               max_length=100,\n",
    "               temperature=1,\n",
    "               top_p=1.5,\n",
    "               return_as_list=True)\n",
    "for l in list:\n",
    "    fix_grammar(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAndre G\u001b[0m.S.\n",
      "re all self-obsessed, delicate, dainty, insecure little souls, and absolute psychopaths. Every last one of them.\n",
      "\n",
      "==========\n",
      "\u001b[1mAndre G\u001b[0m.\n",
      "Im Gordon Ramsay, for goodness sake; people know Im volatile.\n",
      "\n",
      "==========\n",
      "\u001b[1mAndre G\u001b[0m.S.\n",
      "\n",
      "\n",
      " are nutters.\n",
      "\n",
      "==========\n",
      "\u001b[1mAndre G\u001b[0m.\n",
      ". And shes dead!\n",
      "\n",
      "==========\n",
      "\u001b[1mAndre G\u001b[0mata.'\n",
      ".\n",
      "akuna Matata.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gordon Ramsey Generate\n",
    "gr_ai.generate(n=5, \n",
    "               batch_size=5, \n",
    "               prompt=\"Andre G\", \n",
    "               min_length=10,\n",
    "               max_length=100, \n",
    "               temperature=1, \n",
    "               top_p=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jasonisdumb",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "jasondumb",
   "resource_dir": "/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/.local/share/jupyter/kernels/jasondumb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}